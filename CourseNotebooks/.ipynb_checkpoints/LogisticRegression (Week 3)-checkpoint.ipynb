{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - [Week 3](https://www.coursera.org/learn/machine-learning/home/week/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start off with binary classification where $0 \\leq h_\\theta(x) \\leq 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis function is a Sigmoid or Logistic function.  It looks like $h_\\theta(x)=\\frac{1}{1 + e^{-\\theta^Tx}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the results as a probablity of y = 1.  This looks like this mathematically:  $h_\\theta(x)=P(y=1|x;\\theta)$.  So to account for y = 1 and y = 0, the two must equal 1.  The equation looks like this: $h_\\theta(x)=P(y=0|x;\\theta)+P(y=1|x;\\theta)=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function...\n",
    "$J(\\theta) = \\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}Cost(h_\\theta(x^{(i)}),y^{(i)})$ with the Cost term as...\n",
    "\n",
    "$Cost(h_\\theta(x),y) = \n",
    "    \\begin{cases}\n",
    "       -log(h_\\theta(x))     & \\quad \\text {if } y = 1\\\\\n",
    "       -log(1 - h_\\theta(x)) & \\quad \\text {if } y = 0\n",
    "    \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So the ending cost function can be written like so:\n",
    "$J(\\theta) = -\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}\\Bigg[y^{(i)}log(h_\\theta(x^{(i)})) + (1 - y^{(i)})log(1 - h_\\theta(x^{(i)}))\\Bigg]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Optimization...\n",
    "\n",
    "Can use the Octave function ```fminunc``` to compute the learning rate for you as well as tap into a highly optimized method for expediting convergence.  This works for Linear Regression as well as Logistic Regression and is useful on large ML problems.  ```fminunc``` requires a pointer to a custom cost function, an initial column vector for $\\theta$, and an ```options``` data structure. Dr. Ng calls it \"Gradient Descent on steroids\". üòÅ  See the documentation for more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fminunc' is a function from the file /usr/local/octave/3.8.0/share/octave/3.8.0/m/optimization/fminunc.m\n",
      "\n",
      " -- Function File: fminunc (FCN, X0)\n",
      " -- Function File: fminunc (FCN, X0, OPTIONS)\n",
      " -- Function File: [X, FVEC, INFO, OUTPUT, GRAD, HESS] = fminunc (FCN,\n",
      "          ...)\n",
      "     Solve an unconstrained optimization problem defined by the function\n",
      "     FCN.\n",
      "\n",
      "     FCN should accepts a vector (array) defining the unknown variables,\n",
      "     and return the objective function value, optionally with gradient.\n",
      "     In other words, this function attempts to determine a vector X such\n",
      "     that 'FCN (X)' is a local minimum.  X0 determines a starting guess.\n",
      "     The shape of X0 is preserved in all calls to FCN, but otherwise is\n",
      "     treated as a column vector.  OPTIONS is a structure specifying\n",
      "     additional options.  Currently, 'fminunc' recognizes these options:\n",
      "     \"FunValCheck\", \"OutputFcn\", \"TolX\", \"TolFun\", \"MaxIter\",\n",
      "     \"MaxFunEvals\", \"GradObj\", \"FinDiffType\", \"TypicalX\", \"AutoScaling\".\n",
      "\n",
      "     If \"GradObj\" is \"on\", it specifies that FCN, called with 2 output\n",
      "     arguments, also returns the Jacobian matrix of right-hand sides at\n",
      "     the requested point.  \"TolX\" specifies the termination tolerance in\n",
      "     the unknown variables, while \"TolFun\" is a tolerance for equations.\n",
      "     Default is '1e-7' for both \"TolX\" and \"TolFun\".\n",
      "\n",
      "     For description of the other options, see 'optimset'.\n",
      "\n",
      "     On return, FVAL contains the value of the function FCN evaluated at\n",
      "     X, and INFO may be one of the following values:\n",
      "\n",
      "     1\n",
      "          Converged to a solution point.  Relative gradient error is\n",
      "          less than specified by TolFun.\n",
      "\n",
      "     2\n",
      "          Last relative step size was less that TolX.\n",
      "\n",
      "     3\n",
      "          Last relative decrease in function value was less than TolF.\n",
      "\n",
      "     0\n",
      "          Iteration limit exceeded.\n",
      "\n",
      "     -3\n",
      "          The trust region radius became excessively small.\n",
      "\n",
      "     Optionally, fminunc can also yield a structure with convergence\n",
      "     statistics (OUTPUT), the output gradient (GRAD) and approximate\n",
      "     Hessian (HESS).\n",
      "\n",
      "     Notes: If you only have a single nonlinear equation of one variable\n",
      "     then using 'fminbnd' is usually a much better idea.  The algorithm\n",
      "     used is a gradient search which depends on the objective function\n",
      "     being differentiable.  If the function has discontinuities it may\n",
      "     be better to use a derivative-free algorithm such as 'fminsearch'.\n",
      "\n",
      "     See also: fminbnd, fminsearch, optimset.\n",
      "\n",
      "\n",
      "Additional help for built-in functions and operators is\n",
      "available in the online version of the manual.  Use the command\n",
      "'doc <topic>' to search the manual index.\n",
      "\n",
      "Help and information about Octave is also available on the WWW\n",
      "at http://www.octave.org and via the help@octave.org\n",
      "mailing list.\n"
     ]
    }
   ],
   "source": [
    "help fminunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic premise is you create a function that returns a value for $J(\\theta)$ as well as a gradient vector that contains partial derivatives given an initial column vector of \n",
    "$\\theta = \\begin{bmatrix}\n",
    "          \\theta_1 \\\\\n",
    "          \\theta_2 \\\\\n",
    "          \\vdots \\\\\n",
    "          \\theta_n \\\\\n",
    "          \\end{bmatrix}$\n",
    "          \n",
    "Each gradient index stores the partial derivative of $\\theta$ for each index of $\\theta$.  Here's an example given a cost function of $J(\\theta) = (\\theta_1 - 5)^2 + (\\theta_2 - 5)^2$ and a partial derivative for $\\theta_1$ of $\\frac{\\partial}{\\partial\\theta_1}J(\\theta) = 2(\\theta_1 - 5)$ and a partial derivative for $\\theta_2$ of $\\frac{\\partial}{\\partial\\theta_2}J(\\theta) = 2(\\theta_2 - 5)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function [jVal, gradient] = costFunction(theta)\n",
    "    jVal = (theta(1)-5)^2 + (theta(2)-5)^2;\n",
    "    gradient = zeros(2,1);\n",
    "    gradient(1) = 2*(theta(1)-5);\n",
    "    gradient(2) = 2*(theta(2)-5);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optTheta =\n",
      "\n",
      "   5.0000\n",
      "   5.0000\n",
      "\n",
      "functionVal =    7.8886e-31\n",
      "exitFlag =  1\n"
     ]
    }
   ],
   "source": [
    "options = optimset('GradObj','on','MaxIter','100');\n",
    "initialTheta = zeros(2,1);\n",
    "[optTheta, functionVal, exitFlag] = fminunc(@costFunction,initialTheta,options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal values of $\\theta_1$ and $\\theta_2$ respectively are 5 and 5.  The ```functionVal``` is basically 0 and the ```exitFlag``` shows that Gradient Descent did converge.  For ```fminunc``` to work, $\\theta$ needs to generally be >= a 2 dimensional column vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification...\n",
    "\n",
    "Works the same as binary, but are actually training $n$ number of models given $n$ number of classes.  So, given that $y \\in \\{0,1...n\\}$ we create a classification of each class vs. every other class (the *One-vs-all* or *One-vs-rest*) strategy such that:\n",
    "\n",
    "${h_\\theta}^{(0)}(x) = P(y = 0|x;\\theta)$...${h_\\theta}^{(n)}(x) = P(y = n|x;\\theta)$\n",
    "\n",
    "You then would make your prediction based on the maximum probability revealed by each classification model such that:\n",
    "\n",
    "$prediction = max_i(h_\\theta^{(i)}(x))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting...\n",
    "\n",
    "Underfitting = *High Bias* meaning that a model has a preconceived notion of how the data should fit despite the data's \"evidence to the contrary\" per Dr. Ng.  Doesn't even fit the training data very well.\n",
    "\n",
    "Overfitting = *High Variance* meaning the \"space of hypotheses is too large or too variable and we don't have enough data to constrain it to give us a good hypothesis\" - Dr. Ng.  Doesn't generalize very well but fits the training data *too* well.\n",
    "\n",
    "***Lots of features and few training data samples = Overfitting.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to combat overfitting:\n",
    "1. Reduce the number of features\n",
    "    - Manually select which features to keep. (the features may contain useful information though)\n",
    "    - Use a model selection algorithm\n",
    "   \n",
    "   \n",
    "2. Regularization\n",
    "    - Keep all the features but reduce the magnitude of parameters $\\theta_j$.\n",
    "    - Regularization works well when we have a lot of slightly useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization defined...\n",
    "\n",
    "Basically, for higher order terms in a function, like $^3$ or $^4$ or whatever in an overfitting scenario, penalizing those values helps reduce the overfitting.  You do this by setting those higher order features to be large values so when the cost is minimized, the values for the higher order terms approach 0.  By doing this, you end up with a function (like a quadratic) that is much more generalizable.  Note however that quadratic functions may or may not be a good fit for predicting something like the cost of a house in Exercise 1.  A quadratic function is usually parabolic and that doesn't make sense for housing price data based solely on square footage, for example.  As the square footage increases, the price will not likely ever turn downward.  Yet, a quadratic function will at some point turn downward.\n",
    "\n",
    "Regularization allows for \"simpler\" hypotheses.\n",
    "\n",
    "However, how do you tell which feature to penalize when just looking at the data?  We do this by adding a \"regularization parameter\" of $\\lambda\\displaystyle\\sum_{j=1}^{n}\\theta_j^2$ to our cost function.  \n",
    "Given a cost function like we saw with linear regression of $J(\\theta) = \\frac{1}{2m}\\big[\\displaystyle\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda\\displaystyle\\sum_{j=1}^{n}\\theta_j^2\\big]$, the regularization parameter, $\\lambda$, balances the \"tradeoff\" of fitting the training set well (the first term in brackets), but also keeping the parameters as small as possible (the second term in brackets).  Too large of a value for $\\lambda$ can result in penalization of all features though, and will result in underfitting of the training set.  The hypothesis would demonstrate a high bias towards the data (i.e:  a constant price no matter what the size of the house as shown by a horizontal line).  This obviously isn't a good, generalizable hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Linear Regression..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regularized linear regression cost function looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J(\\theta) = \\frac{1}{2m}\\Bigg[\\displaystyle\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda\\displaystyle\\sum_{j=1}^{n}\\theta_j^2\\Bigg]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regularized Gradient Descent algorithm looks like this...\n",
    "\n",
    "We don't penalize $\\theta_0$.  So $\\theta_0$ continues to look like this (no change from before):\n",
    "\n",
    "$\\theta_0 := \\theta_0 - \\alpha\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_0$\n",
    "\n",
    "But we do penalize the other features using a simplified regularization parameter:\n",
    "\n",
    "$\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j + \\frac{\\lambda}{m}\\theta_j$\n",
    "\n",
    "***NOTE: $h_\\theta(x)$ is the hyptothesis function for Linear Regression: $h_\\theta(x) = \\theta^Tx$*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regularized Normal equation looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta =  \\Bigg(X^TX + \\lambda\\begin{bmatrix}\n",
    "                          0 0 0 0 0\\\\\n",
    "                          0 1 0 0 0\\\\\n",
    "                          0 0 1 0 0\\\\\n",
    "                             \\ddots\\\\\n",
    "                          0 0 0 0 1\n",
    "                          \\end{bmatrix}\n",
    "\\Bigg)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed previously with the Normal equation, rarely, the $X^TX$ term can be non-invertible a.k.a \"degenerate\" or \"singular\".  This occurs when the number of training samples is <= the number of features.  However, using a regularization term and if $\\lambda > 0$, then the $X^TX$ term will always be invertible.  So, regularization actually helps ensure $X^TX$ is always invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A regularized logistic regression cost function looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$J(\\theta) = -\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}\\Bigg[y^{(i)}log(h_\\theta(x^{(i)})) + (1 - y^{(i)})log(1 - h_\\theta(x^{(i)}))\\Bigg] + \\frac{\\lambda}{2m}\\displaystyle\\sum_{j=1}^{n}\\theta_j^2\\Bigg]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regularized logistic regression, we use the same modified Gradient Descent algorithm as above with a regularization parameter:\n",
    "\n",
    "Again, we don't penalize $\\theta_0$.  So $\\theta_0$ continues to look like this (no change from before):\n",
    "\n",
    "$\\theta_0 := \\theta_0 - \\alpha\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_0$\n",
    "\n",
    "But we do penalize the other features using a simplified regularization parameter:\n",
    "\n",
    "$\\theta_j := \\theta_j - \\alpha\\frac{1}{m}\\displaystyle\\sum_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j + \\frac{\\lambda}{m}\\theta_j$\n",
    "\n",
    "***NOTE: $h_\\theta(x)$ is the hyptothesis function for Logistic Regression (the Sigmoid function): $h_\\theta(x)=\\frac{1}{1 + e^{-\\theta^Tx}}$*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See slides for Lecture 7 (page 23) for how to implement advanced optimization (i.e: used with ```fminunc``` ) with regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
